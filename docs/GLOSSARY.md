# Glossary

| Term                               | Definition                                                                                                                                                                                                                                                                                                                                                       |
|------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **@ExploreExperiment**             | Annotation for EXPLORE mode: comparing multiple configurations with fewer samples each.                                                                                                                                                                                                                                                                          |
| **@MeasureExperiment**             | Annotation for MEASURE mode: precise estimation of one configuration with many samples to establish a baseline.                                                                                                                                                                                                                                                  |
| **@OptimizeExperiment**            | Annotation for OPTIMIZE mode: tuning a single factor to find the optimal value.                                                                                                                                                                                                                                                                                  |
| **Backend**                        | A pluggable component providing domain-specific configuration.                                                                                                                                                                                                                                                                                                   |
| **Baseline Selection**             | The process of choosing the most appropriate baseline for a probabilistic test based on footprint match and covariate conformance. When multiple baselines exist, the one with the best covariate match is selected.                                                                                                                                             |
| **Compliance Testing**             | Verifying a system meets a mandated threshold (SLA, SLO, policy).                                                                                                                                                                                                                                                                                                |
| **Conformance Testing**            | Detecting when performance regresses below an empirically established baseline.                                                                                                                                                                                                                                                                                  |
| **confidence**                     | Probability of a correct verdict; equals 1 minus the false positive rate. Part of the parameter triangle.                                                                                                                                                                                                                                                        |
| **Confidence-First Approach**      | User specifies confidence + power + minDetectableEffect; framework computes required samples.                                                                                                                                                                                                                                                                    |
| **Contract Reference**             | Human-readable string identifying the document/clause defining a test threshold.                                                                                                                                                                                                                                                                                 |
| **Covariate**                      | A contextual factor that drives variance in system behavior. Covariates are declared on a use case to indicate which environmental or configuration variables should be tracked for baseline matching and statistical comparison. Unlike functional inputs (Factors), covariates represent conditions that affect outcomes but are often outside direct control. |
| **Covariate Category**             | Classification of a covariate by its nature: TEMPORAL (time-based), CONFIGURATION (deliberate choices), EXTERNAL_DEPENDENCY (third-party services), INFRASTRUCTURE (execution environment), DATA_STATE (data context), or INFORMATIONAL (traceability only).                                                                                                     |
| **Covariate Conformance**          | The degree to which a test's covariate values match those of the baseline. Full conformance means all covariates match; non-conformance indicates the test ran under different conditions than the baseline was established.                                                                                                                                     |
| **Covariate Profile**              | An immutable record of covariate values captured at a specific point in time, used to characterize the conditions under which an experiment or test was executed.                                                                                                                                                                                                |
| **Duration Constraint**            | A timing requirement in a ServiceContract specifying the maximum allowed execution duration. Evaluated independently from postconditions, providing a parallel dimension for "was it fast enough?" alongside "was it correct?".                                                                                                                                  |
| **Effect Size**                    | The minimum degradation the test is designed to detect (same as minDetectableEffect).                                                                                                                                                                                                                                                                            |
| **Empirical Baseline**             | Machine-generated record of observed behavior.                                                                                                                                                                                                                                                                                                                   |
| **Execution Specification**        | Human-approved contract derived from baselines.                                                                                                                                                                                                                                                                                                                  |
| **Experiment**                     | Executes a use case across one or more `ExperimentConfig`s in exploratory mode.                                                                                                                                                                                                                                                                                  |
| **ExperimentConfig**               | One concrete combination of levels—the unit of execution.                                                                                                                                                                                                                                                                                                        |
| **ExperimentDesign**               | Declarative description of what is explored (factors + levels).                                                                                                                                                                                                                                                                                                  |
| **ExperimentFactor**               | One independently varied dimension (e.g., `model`, `temperature`).                                                                                                                                                                                                                                                                                               |
| **ExperimentGoal**                 | Optional criteria for early termination.                                                                                                                                                                                                                                                                                                                         |
| **ExperimentLevel**                | One setting of a factor (categorical or numeric).                                                                                                                                                                                                                                                                                                                |
| **Factor**                         | One independently varied dimension in EXPLORE mode (e.g., `model`, `temperature`).                                                                                                                                                                                                                                                                               |
| **FactorSource**                   | JUnit-style source of factor combinations (e.g., `@MethodSource`, `@CsvFactorSource`).                                                                                                                                                                                                                                                                           |
| **FailureCategorizer**             | Function that classifies failed samples into categories.                                                                                                                                                                                                                                                                                                         |
| **False Negative (Type II Error)** | A test pass when the system has degraded.                                                                                                                                                                                                                                                                                                                        |
| **False Positive (Type I Error)**  | A test failure when the system has not degraded.                                                                                                                                                                                                                                                                                                                 |
| **Footprint**                      | A stable hash identifying the combination of use case identity, functional parameters, and covariate declarations. Two baselines with the same footprint are candidates for covariate-based selection.                                                                                                                                                           |
| **Input**                          | Annotation marking a parameter as the target for input injection from `@InputSource`.                                                                                                                                                                                                                                                                            |
| **InputSource**                    | Annotation providing test inputs from a method or file, distributed across samples.                                                                                                                                                                                                                                                                              |
| **Instance Conformance**           | Validation that actual results match expected values                                                                                                                                                                                                                                                                                                             |
| **llmx**                           | The LLM-specific backend extension.                                                                                                                                                                                                                                                                                                                              |
| **minDetectableEffect**            | Smallest drop from baseline worth detecting; required for Confidence-First approach to compute sample size.                                                                                                                                                                                                                                                      |
| **minPassRate**                    | The threshold pass rate the system must meet to pass the test. Part of the parameter triangle.                                                                                                                                                                                                                                                                   |
| **One-Sided Lower Bound**          | Statistical threshold below which true success rate is unlikely to fall.                                                                                                                                                                                                                                                                                         |
| **Parameter Triangle**             | The three interdependent parameters in probabilistic testing: samples, confidence, and minPassRate. You control two; statistics determines the third.                                                                                                                                                                                                            |
| **power**                          | Probability of catching a real degradation; equals 1 minus the false negative rate.                                                                                                                                                                                                                                                                              |
| **PromptContributor**              | Interface for extracting prompt components from production code.                                                                                                                                                                                                                                                                                                 |
| **Provenance**                     | The chain of artifacts from definition to enforcement.                                                                                                                                                                                                                                                                                                           |
| **punit-statistics Module**        | Isolated module for all statistical calculations.                                                                                                                                                                                                                                                                                                                |
| **RegressionThreshold**            | Statistically-derived minimum pass rate for regression tests.                                                                                                                                                                                                                                                                                                    |
| **Sample-Size-First Approach**     | User specifies samples + confidence; framework computes achievable threshold.                                                                                                                                                                                                                                                                                    |
| **Sample**                         | A single execution of the system under test.                                                                                                                                                                                                                                                                                                                     |
| **samples**                        | Number of test executions; controls cost and time. Part of the parameter triangle.                                                                                                                                                                                                                                                                               |
| **SLA (Service Level Agreement)**  | Contractual commitment to external customers defining minimum service quality.                                                                                                                                                                                                                                                                                   |
| **SLO (Service Level Objective)**  | Internal target for service quality, often more stringent than SLAs.                                                                                                                                                                                                                                                                                             |
| **Spec**                           | YAML file containing baseline measurements and metadata.                                                                                                                                                                                                                                                                                                         |
| **Statistical Power**              | The probability of correctly detecting a real degradation (1-β); same as power parameter.                                                                                                                                                                                                                                                                        |
| **Service Contract**               | A formal definition of what "success" means for a **Use Case**. It contains postconditions (and optional timing constraints) that determine whether a sample should count as a success. Used by both experiments (to measure behavior) and probabilistic tests (to enforce correctness).                                                                         |
| **thresholdConfidence**            | Confidence level used for deriving minPassRate from observed results in Sample-Size-First approach.                                                                                                                                                                                                                                                              |
| **Threshold-First Approach**       | User specifies samples + threshold; framework computes implied confidence.                                                                                                                                                                                                                                                                                       |
| **Threshold Origin**               | Enum indicating the origin of a probabilistic test's threshold (e.g., SLA, SLO, POLICY). Origins marked as normative (SLA/SLO/POLICY) trigger stricter enforcement rules for VERIFICATION intent.                                                                                                                                                                |
| **Threshold Provenance**           | Optional metadata documenting where a test's threshold originated (SLA, SLO, policy, etc.).                                                                                                                                                                                                                                                                      |
| **TokenEstimator**                 | Interface for estimating token counts when providers don't report them.                                                                                                                                                                                                                                                                                          |
| **Use Case**                       | An artifact defining a service operation and its **Service Contract**. It ensures that experiments and tests refer to the same expression of correctness. In implementation, a Use Case invokes production code and returns a `UseCaseOutcome`.                                                                                                                  |
| **Use Case ID**                    | A unique string identifier for a use case (e.g., `usecase.json.generation`).                                                                                                                                                                                                                                                                                     |
| **UseCaseResult**                  | A neutral container of key-value observations produced by a use case invocation.                                                                                                                                                                                                                                                                                 |
| **Wilson Score Bound**             | Robust confidence bound for binomial proportions.                                                                                                                                                                                                                                                                                                                |
| **TestIntent**                     | Declares the developer's intent for a probabilistic test: `VERIFICATION` (evidential, configuration must be statistically feasible for normative thresholds) or `SMOKE` (sentinel, undersized configs allowed but verdicts are caveated).                                                                                                                        |
| **Normative (Threshold Origin)**   | A threshold origin that represents a requirement (SLA/SLO/POLICY). With VERIFICATION intent, insufficient sample sizes cause the test to be rejected before execution; with SMOKE intent, the test runs but verdicts include an explicit caveat.                                                                                                                 |