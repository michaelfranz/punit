package org.javai.punit.examples.usecases;

import org.javai.outcome.Outcome;
import org.javai.punit.api.Covariate;
import org.javai.punit.api.CovariateCategory;
import org.javai.punit.api.CovariateSource;
import org.javai.punit.api.FactorGetter;
import org.javai.punit.api.FactorSetter;
import org.javai.punit.api.StandardCovariate;
import org.javai.punit.api.UseCase;
import org.javai.punit.contract.ServiceContract;
import org.javai.punit.contract.UseCaseOutcome;
import org.javai.punit.contract.match.JsonMatcher;
import org.javai.punit.examples.infrastructure.llm.ChatLlm;
import org.javai.punit.examples.infrastructure.llm.ChatLlmProvider;
import org.javai.punit.examples.infrastructure.llm.ChatResponse;
import org.jspecify.annotations.NonNull;

/**
 * Use case for translating natural language shopping instructions to structured actions.
 *
 * <p>This use case demonstrates the <b>empirical approach</b> to probabilistic testing,
 * where thresholds are derived from measured baselines rather than external contracts.
 *
 * <h2>Domain</h2>
 * <p>A user provides natural language instructions like "Add 2 apples" or "Clear the basket",
 * and an LLM translates these into structured {@link ShoppingAction} objects that can be
 * executed against a shopping basket API.
 *
 * <h2>JSON Format</h2>
 * <pre>{@code
 * {
 *   "context": "SHOP",
 *   "name": "add",
 *   "parameters": [
 *     {"name": "item", "value": "apple"},
 *     {"name": "quantity", "value": "2"}
 *   ]
 * }
 * }</pre>
 *
 * <h2>Success Criteria</h2>
 * <ol>
 *   <li>Valid JSON (parseable)</li>
 *   <li>Deserializes to a valid {@link ShoppingAction}</li>
 *   <li>Action name is valid for the given context</li>
 * </ol>
 *
 * <h2>Covariates</h2>
 * <p>This use case tracks covariates that may affect LLM behavior:
 * <ul>
 *   <li>{@code WEEKDAY_VERSUS_WEEKEND} - Temporal context (TEMPORAL)</li>
 *   <li>{@code TIME_OF_DAY} - Temporal context (TEMPORAL)</li>
 *   <li>{@code llm_model} - Which model is being used (CONFIGURATION)</li>
 *   <li>{@code temperature} - Temperature setting (CONFIGURATION)</li>
 * </ul>
 *
 * @see ShoppingAction
 * @see ShoppingActionValidator
 */
@UseCase(
        description = "Translate natural language shopping instructions to structured actions",
        covariates = {StandardCovariate.WEEKDAY_VERSUS_WEEKEND, StandardCovariate.TIME_OF_DAY},
        categorizedCovariates = {
                @Covariate(key = "llm_model", category = CovariateCategory.CONFIGURATION),
                @Covariate(key = "temperature", category = CovariateCategory.CONFIGURATION)
        }
)
public class ShoppingBasketUseCase {

    /**
     * Input parameters for the translation service.
     */
    private record ServiceInput(String systemPrompt, String instruction, String model, double temperature) {}

    /**
     * The service contract defining postconditions for translation results.
     */
    private static final ServiceContract<ServiceInput, ChatResponse> CONTRACT =
            ServiceContract.<ServiceInput, ChatResponse>define()
                    .ensure("Response has content", ShoppingBasketUseCase::getResponseHasContentOutcome)
                    .derive("Valid shopping action", ShoppingActionValidator::validate)
                    .ensure("Contains valid actions", ShoppingBasketUseCase::getValidActionOutcome)
                    .build();

    private static @NonNull Outcome<Void> getResponseHasContentOutcome(ChatResponse response) {
        return response.content() != null && !response.content().isBlank()
                ? Outcome.ok()
                : Outcome.fail("check", "content was null or blank");
    }

    private static @NonNull Outcome<Void> getValidActionOutcome(ShoppingActionValidator.ValidationResult result) {
        if (result.actions().isEmpty()) {
            return Outcome.fail("check", "No actions in result");
        }
        for (ShoppingAction action : result.actions()) {
            if (!action.context().isValidAction(action.name())) {
                return Outcome.fail("check",
                        "Invalid action '%s' for context %s"
                                .formatted(action.name(), action.context()));
            }
        }
        return Outcome.ok();
    }

    private final ChatLlm llm;
    private String model = "gpt-4o-mini";
    private double temperature = 0.3;
    private String systemPrompt = """
            You are a shopping assistant that converts natural language instructions into JSON actions.

            ALWAYS respond with a JSON object containing an "actions" array, even for single operations.

            Format:
            {
              "actions": [
                {
                  "context": "SHOP",
                  "name": "<action>",
                  "parameters": [
                    {"name": "item", "value": "<item_name>"},
                    {"name": "quantity", "value": "<number>"}
                  ]
                }
              ]
            }

            Valid actions for SHOP context: "add", "remove", "clear"
            For "clear" actions, parameters may be empty.

            Examples:
            - "Add 2 apples" -> {"actions": [{"context": "SHOP", "name": "add", "parameters": [{"name": "item", "value": "apples"}, {"name": "quantity", "value": "2"}]}]}
            - "Add apples and remove milk" -> {"actions": [{"context": "SHOP", "name": "add", "parameters": [{"name": "item", "value": "apples"}, {"name": "quantity", "value": "1"}]}, {"context": "SHOP", "name": "remove", "parameters": [{"name": "item", "value": "milk"}]}]}
            - "Clear the basket" -> {"actions": [{"context": "SHOP", "name": "clear", "parameters": []}]}
            """;

    /**
     * Creates a use case with the LLM resolved from configuration.
     *
     * @see ChatLlmProvider#resolve()
     */
    public ShoppingBasketUseCase() {
        this(ChatLlmProvider.resolve());
    }

    /**
     * Creates a use case with a specific LLM implementation.
     *
     * @param llm the chat LLM to use
     */
    public ShoppingBasketUseCase(ChatLlm llm) {
        this.llm = llm;
    }

    // ═══════════════════════════════════════════════════════════════════════════
    // FACTOR GETTERS AND COVARIATE SOURCES
    // ═══════════════════════════════════════════════════════════════════════════

    @FactorGetter
    @CovariateSource("llm_model")
    public String getModel() {
        return model;
    }

    @FactorGetter
    @CovariateSource
    public double getTemperature() {
        return temperature;
    }

    @FactorGetter
    public String getSystemPrompt() {
        return systemPrompt;
    }

    // ═══════════════════════════════════════════════════════════════════════════
    // FACTOR SETTERS
    // ═══════════════════════════════════════════════════════════════════════════

    @FactorSetter("llm_model")
    public void setModel(String model) {
        this.model = model;
    }

    @FactorSetter
    public void setTemperature(double temperature) {
        this.temperature = temperature;
    }

    @FactorSetter
    public void setSystemPrompt(String systemPrompt) {
        this.systemPrompt = systemPrompt;
    }

    /**
     * Returns the cumulative tokens used by the underlying LLM since the last reset.
     *
     * @return total tokens across all calls
     */
    public long getTotalTokensUsed() {
        return llm.getTotalTokensUsed();
    }

    /**
     * Resets the cumulative token counter in the underlying LLM.
     */
    public void resetTokenCount() {
        llm.resetTokenCount();
    }

    // ═══════════════════════════════════════════════════════════════════════════
    // USE CASE METHODS
    // ═══════════════════════════════════════════════════════════════════════════

    /**
     * Translates a natural language shopping instruction to a structured action.
     *
     * @param instruction the natural language instruction (e.g., "Add 2 apples")
     * @return outcome containing the result and postcondition evaluations
     */
    public UseCaseOutcome<ChatResponse> translateInstruction(String instruction) {
        return translateInstructionCore(instruction, null);
    }

    /**
     * Translates a natural language shopping instruction to a structured action,
     * with instance conformance checking against an expected JSON result.
     *
     * <p>This method extends {@link #translateInstruction(String)} by also comparing
     * the actual LLM response against the expected JSON. The comparison is semantic,
     * meaning JSON property order and whitespace differences are ignored.
     *
     * <p>Use {@link UseCaseOutcome#fullySatisfied()} to check both behavioral conformance
     * (postconditions) and instance conformance (expected value match).
     *
     * @param instruction the natural language instruction (e.g., "Add 2 apples")
     * @param expectedJson the expected JSON response for instance conformance checking
     * @return outcome containing the result, postcondition evaluations, and match result
     */
    public UseCaseOutcome<ChatResponse> translateInstruction(String instruction, String expectedJson) {
        return translateInstructionCore(instruction, expectedJson);
    }

    private UseCaseOutcome<ChatResponse> translateInstructionCore(String instruction, String expectedJson) {
        var builder = UseCaseOutcome
                .withContract(CONTRACT)
                .input(new ServiceInput(systemPrompt, instruction, model, temperature))
                .execute(this::executeTranslation)
                .withResult((response, meta) -> meta
                        .meta("tokensUsed", response.totalTokens())
                        .meta("promptTokens", response.promptTokens())
                        .meta("completionTokens", response.completionTokens()));

        if (expectedJson != null) {
            builder.expecting(expectedJson, ChatResponse::content, JsonMatcher.create());
        }

        return builder
                .meta("instruction", instruction)
                .meta("model", model)
                .meta("temperature", temperature)
                .build();
    }

    private ChatResponse executeTranslation(ServiceInput input) {
        return llm.chatWithMetadata(
                input.systemPrompt(),
                input.instruction(),
                input.model(),
                input.temperature()
        );
    }
}
